//===- LinalgOps.td - Linalg dialect ops -------------------*- tablegen -*-===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//
//
// This is the operation definition file for linear algebra operations.
//
//===----------------------------------------------------------------------===//

#ifndef LINALG_OPS
#define LINALG_OPS

include "mlir/Dialect/Linalg/IR/LinalgBase.td"
include "mlir/Dialect/Linalg/IR/LinalgInterfaces.td"
include "mlir/Interfaces/ControlFlowInterfaces.td"
include "mlir/Interfaces/InferTypeOpInterface.td"
include "mlir/Interfaces/LoopLikeInterface.td"
include "mlir/Interfaces/SideEffectInterfaces.td"
include "mlir/Interfaces/ViewLikeInterface.td"

// Base class for Linalg dialect ops that do not correspond to library calls.
class Linalg_Op<string mnemonic, list<Trait> traits = []> :
    Op<Linalg_Dialect, mnemonic, traits>;

def Linalg_InitTensorOp : Linalg_Op<"init_tensor",
    [NoSideEffect,
     DeclareOpInterfaceMethods<ReifyRankedShapedTypeOpInterface>]> {
  let summary = "operation to define a tensor of particular shape";

  let description = [{
    `linalg.init_tensor` is an operation that defines a tensor of a particular
    shape. The shape could be dynamic or static. The contents of the tensor are
    unspecified and the only purpose of the op result is to materialize the
    specified shape in IR and make it available to other transformations.

    Note: This op can be lowered to a `bufferization.alloc_tensor`, at which
    point it turns into an explicit buffer allocation.
  }];

  let arguments =
    (ins Variadic<Index>:$sizes, I64ArrayAttr:$static_sizes);

  let results = (outs AnyTensor:$result);

  let assemblyFormat = [{
    custom<DynamicIndexList>($sizes, $static_sizes,
                               "ShapedType::kDynamicSize")
    attr-dict `:` type($result)
  }];

  let extraClassDeclaration = [{
    static StringRef getStaticSizesAttrStrName() {
      return "static_sizes";
    }

    RankedTensorType getType() {
      return getResult().getType().cast<RankedTensorType>(); }

    // Infer the shape of the result tensor given the static shapes
    // and element type of the result tensor.
    static Type inferResultType(ArrayRef<int64_t> staticSizes, Type elementType,
                                Attribute encoding = {});

    // Return true if the size of the tensor is dynamic at `idx`
    bool isDynamicSize(unsigned idx) {
      APInt v = *(getStaticSizes().getAsValueRange<IntegerAttr>().begin() + idx);
      return ShapedType::isDynamic(v.getSExtValue());
    }

    // Assert that the size of the result tensor is static at `idx`
    // and return the shape.
    int64_t getStaticSize(unsigned idx) {
      assert(!isDynamicSize(idx) && "expected static size");
      APInt v = *(getStaticSizes().
          template getAsValueRange<IntegerAttr>().begin() + idx);
        return v.getSExtValue();
    }

    // Return the argument position that contains the dynamic size of
    // the tensor at dimension `idx`. Asserts that the shape is
    // dynamic at that `idx`.
    unsigned getIndexOfDynamicSize(unsigned idx) {
      assert(isDynamicSize(idx) && "expected dynamic size");
      return std::count_if(
          getStaticSizes().getValue().begin(),
          getStaticSizes().getValue().begin() + idx,
          [&](Attribute attr) {
            return ShapedType::isDynamic(attr.cast<IntegerAttr>().getInt());
          });
    }

    // Return both static and dynamic sizes as a list of `OpFoldResult`.
    SmallVector<OpFoldResult> getMixedSizes();

    // Return the Value of the dynamic size of the tensor at dimension
    // `idx`. Asserts that the shape is dynamic at that `idx.
    Value getDynamicSize(unsigned idx) {
      return getOperand(getIndexOfDynamicSize(idx));
    }
  }];

  let builders = [
    OpBuilder<(ins "ValueRange":$shape,
                  "ArrayRef<int64_t>":$staticShape, "Type":$elementType),
    [{
      build($_builder, $_state,
            InitTensorOp::inferResultType(staticShape, elementType),
            shape, $_builder.getI64ArrayAttr(staticShape));
    }]>,
    OpBuilder<(ins "ValueRange":$shape, "Type":$elementType),
    [{
      SmallVector<int64_t, 4> staticShape(
        shape.size(), ShapedType::kDynamicSize);
      build($_builder, $_state, shape, staticShape, elementType);
    }]>,
    OpBuilder<(ins "ArrayRef<int64_t>":$staticShape, "Type":$elementType),
    [{
      build($_builder, $_state, ValueRange{}, staticShape, elementType);
    }]>,
    OpBuilder<(ins "ArrayRef<OpFoldResult>":$sizes, "Type":$elementType,
      CArg<"ArrayRef<NamedAttribute>", "{}">:$attrs)>
  ];

  let hasCanonicalizer = 1;
  let hasCustomAssemblyFormat = 1;
  let hasVerifier = 1;
}

def Linalg_YieldOp : Linalg_Op<"yield", [NoSideEffect, ReturnLike, Terminator]>,
    Arguments<(ins Variadic<AnyType>:$values)> {
  let summary = "Linalg yield operation";
  let description = [{
    `linalg.yield` is a special terminator operation for blocks inside regions
    in `linalg` generic ops. It returns values to the immediately enclosing
    `linalg` generic op.

    Example:

    ```mlir
    linalg.yield %f0, %f1 : f32, f32
    ```
  }];
  let builders = [OpBuilder<(ins), [{ /* nothing to do */ }]>];
  let hasCustomAssemblyFormat = 1;
  let hasVerifier = 1;
}

def Linalg_IndexOp : Linalg_Op<"index", [NoSideEffect]>,
    Arguments<(ins ConfinedAttr<I64Attr, [IntMinValue<0>]>:$dim)>,
    Results<(outs Index:$result)> {
  let summary = "linalg index operation";
  let description = [{
    The `linalg.index` operation returns the iteration index of the immediately
    enclosing linalg structured operation for the iteration dimension `dim`. The
    `dim` attribute specifies the position of the accessed dimension in the
    indexing map domain.

    Example:

    ```mlir
    #map = affine_map<(i, j) -> (i, j)>
    linalg.generic {indexing_maps = [#map, #map],
                    iterator_types = ["parallel", "parallel"]}
      outs(%I, %J : memref<?x?xindex>, memref<?x?xindex>) {
      ^bb0(%arg0 : index, %arg1 : index):
      // Access the outer iteration dimension i
      %i = linalg.index 0 : index
      // Access the inner iteration dimension j
      %j = linalg.index 1 : index
      linalg.yield %i, %j : index, index
    }
    ```

    This may lower to IR resembling:

    ```mlir
    %0 = dim %I, %c0 : memref<?x?xindex>
    %1 = dim %I, %c1 : memref<?x?xindex>
    scf.for %i = %c0 to %0 step %c1 {
      scf.for %j = %c0 to %1 step %c1 {
        store %i, %I[%i, %j] : memref<?x?xindex>
        store %j, %J[%i, %j] : memref<?x?xindex>
      }
    }
    ```
  }];

  let assemblyFormat = [{ $dim attr-dict `:` type($result) }];
  let hasVerifier = 1;
}

def Linalg_SoftmaxOp : Linalg_Op<"softmax", [NoSideEffect]> {
  let arguments = (ins AnyTensor:$input,
                       I64Attr:$dim);
  let results = (outs AnyTensor:$result);
  let summary = "linalg softmax operation";
  let description = [{
    This implements the softmax operator.
  }];
  let assemblyFormat = [{ attr-dict `ins``(` $input `:` type($input)`)` `->` type(results) }];
  let hasVerifier = 1;
}

def Linalg_GlobalAveragePool2DOp : Linalg_Op<"globalaveragepool2d", [NoSideEffect]> {
  let arguments = (ins AnyTensor:$input);
  let results = (outs AnyTensor:$result);
  let summary = "linalg globalaveragepool2d operation";
  let description = [{
    This implements the globalaveragepool2d operator.
    The custom op is unfused into `linalg.pooling_nchw_sum` and `arith.divf`.
  }];
  let assemblyFormat = [{ attr-dict `ins``(` $input `:` type($input)`)` `->` type(results) }];
  let hasVerifier = 1;
}

def Linalg_Conv2dTensorAddGlobalAveragePoolOp
    : Linalg_Op<"conv_2d_tensor_add_globalaveragepool", [NoSideEffect]> {
  let arguments = (ins AnyTensor:$I,
                       AnyTensor:$J,
                       AnyTensor:$K,
                       AnyTensor:$B,
                       AnyTensor:$O,
                       AnyIntElementsAttr:$strides,
                       AnyIntElementsAttr:$dilations
  );
  let results = (outs AnyTensor:$result);
  let summary = "Conv2D + Tensor-Add + GlobalAveragePool compound operation";
  let description = [{
    Performs fused 2-D convolution, elementwise add and global average pool.

    Layout:
      * Input: NCHW
      * Kernel: FCHW
  }];
  let assemblyFormat = [{
    attr-dict
    `ins``(` $I`,` $J`,` $K`,` $B
      `:` type($I)`,` type($J)`,` type($K)`,` type($B)`)`
    `outs``(` $O `:` type($O)`)`
    `->` type(results)
  }];
  let hasVerifier = 1;
}

def Linalg_Conv2dTensorAddReluGlobalAveragePoolOp
    : Linalg_Op<"conv_2d_tensor_add_relu_globalaveragepool", [NoSideEffect]> {
  let arguments = (ins AnyTensor:$I,
                       AnyTensor:$J,
                       AnyTensor:$K,
                       AnyTensor:$B,
                       AnyTensor:$O,
                       AnyIntElementsAttr:$strides,
                       AnyIntElementsAttr:$dilations
  );
  let results = (outs AnyTensor:$result);
  let summary = [{
    Conv2D + Tensor-Add + ReLU + GlobalAveragePool compound operation
  }];
  let description = [{
    Performs fused 2-D convolution, elementwise add, ReLU and global average
    pool.

    Layout:
      * Input: NCHW
      * Kernel: FCHW
  }];
  let assemblyFormat = [{
    attr-dict
    `ins``(` $I`,` $J`,` $K`,` $B
      `:` type($I)`,` type($J)`,` type($K)`,` type($B)`)`
    `outs``(` $O `:` type($O)`)`
    `->` type(results)
  }];
  let hasVerifier = 1;
}

def Linalg_Conv2dTensorAddLreluGlobalAveragePoolOp
    : Linalg_Op<"conv_2d_tensor_add_lrelu_globalaveragepool", [NoSideEffect]> {
  let arguments = (ins AnyTensor:$I,
                       AnyTensor:$J,
                       AnyTensor:$K,
                       AnyTensor:$B,
                       F32:$alpha,
                       AnyTensor:$O,
                       AnyIntElementsAttr:$strides,
                       AnyIntElementsAttr:$dilations
  );
  let results = (outs AnyTensor:$result);
  let summary = [{
    Conv2D + Tensor-Add + LeakyReLU + GlobalAveragePool compound operation
  }];
  let description = [{
    Performs fused 2-D convolution, elementwise add, LeakyReLU and global
    average pool.

    Layout:
      * Input: NCHW
      * Kernel: FCHW
  }];
  let assemblyFormat = [{
    attr-dict
    `ins``(` $I`,` $J`,` $K`,` $B`,` $alpha
      `:` type($I)`,` type($J)`,` type($K)`,` type($B)`,` type($alpha)`)`
    `outs``(` $O `:` type($O)`)`
    `->` type(results)
  }];
  let hasVerifier = 1;
}

def Linalg_LinearOp : Linalg_Op<"linear", [NoSideEffect]> {
  let arguments = (
    ins AnyTensor:$input, 
        AnyTensor:$weights, 
        AnyTensor:$bias
    );
  let results = (outs AnyTensor:$result);
  let summary = "linalg linear operation (y=A*B^T+C)";
  let description = [{
    The following custom operator implements the linear operator y=A*B^T+C.
    Remember, C is broadcastable, therefore it is of rank 1.
    Linear can be decomposed into two generic linalg operators one broadcasting
    C into 2D tensor, the other transposing the weights. With a linalg matmul
    consuming the input tensor, transposed weights and the broadcasted C tensor.
  }];
  let assemblyFormat = [{ attr-dict `ins``(` $input `:` type($input)`,` $weights `:` type($weights)`,` $bias `:` type($bias) `)` `->` type(results) }];
  let hasVerifier = 1;
}

def Linalg_FusedOp
    : Linalg_Op<"fused", [
        IsolatedFromAbove,
        DeclareOpInterfaceMethods<MemoryEffectsOpInterface>,
        DeclareOpInterfaceMethods<LinalgOperatorClassInterface>,
        DeclareOpInterfaceMethods<
          RegionBranchOpInterface, [
            "getSuccessorEntryOperands",
            "getNumRegionInvocations",
            "getRegionInvocationBounds"]>,
        SingleBlockImplicitTerminator<"YieldOp">]> {
  let summary = "Fused operator region";
  let description = [{
    The `linalg.fused` operation declares a single block that collects
    operations that produce a tensor value in a single fused loop nest, with
    all intermediary values being buffered internally and/or scalar replaced.

    All values used within this block must be explicitly captured.

    This operation also supports buffered semantics, where no value will be
    returned, and all side-effects are expected to be mediated through captured
    memrefs.

    Example:

    ```mlir
    %0 = ... : tensor<1x3x108x108xf32>
    %1 = linalg.fused (%ifm = %0 : tensor<1x3x108x108xf32>) {
      %0 = linalg.conv2d_nchw ins(%ifm: ...
      %1 = linalg.relu2d_nchw ins(%0: ...
      linalg.yield %1 : tensor<1x3x106x106xf32>
    } -> tensor<1x3x106x106xf32>
    ```
  }];

  let arguments = (ins Variadic<AnyType>:$captures);
  let results = (outs Optional<AnyRankedTensor>:$result);
  let regions = (region SizedRegion<1>:$body);

  let hasCustomAssemblyFormat = 1;
  let hasVerifier = 1;
  let hasCanonicalizer = 1;

  let builders = [
    OpBuilder<(ins
      "Type":$resultType,
      "ValueRange":$captures,
      CArg<"function_ref<void(OpBuilder &, Location, BlockAndValueMapping &)>", "nullptr">:$bodyBuilder)>,
    OpBuilder<(ins
      "ValueRange":$captures,
      CArg<"function_ref<void(OpBuilder &, Location, BlockAndValueMapping &)>", "nullptr">:$bodyBuilder)>
  ];
  let skipDefaultBuilders = 1;

  code extraClassDeclaration = [{
    Block::BlockArgListType getCaptureArgs() {
      return getBody()->getArguments();
    }

    BlockAndValueMapping getCaptureMapping() {
      BlockAndValueMapping result;
      for (unsigned idx = 0; idx < captures().size(); ++idx) {
        result.map(captures()[idx], getCaptureArgs()[idx]);
      }
      return result;
    }
    BlockAndValueMapping getUnCaptureMapping() {
      BlockAndValueMapping result;
      for (unsigned idx = 0; idx < captures().size(); ++idx) {
        result.map(getCaptureArgs()[idx], captures()[idx]);
      }
      return result;
    }
  }];
}

#endif // LINALG_OPS
